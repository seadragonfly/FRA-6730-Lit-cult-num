{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44be92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import ast\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "import dateparser\n",
    "\n",
    "\n",
    "IN_FOLDER= '../data/excel'\n",
    "OUT_FOLDER= '../data/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bda65c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>page_start</th>\n",
       "      <th>page_end</th>\n",
       "      <th>titre</th>\n",
       "      <th>sous-titre</th>\n",
       "      <th>dates</th>\n",
       "      <th>salle</th>\n",
       "      <th>auteur</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>mise en scène</th>\n",
       "      <th>...</th>\n",
       "      <th>production</th>\n",
       "      <th>coproduction</th>\n",
       "      <th>soutien</th>\n",
       "      <th>aide</th>\n",
       "      <th>source</th>\n",
       "      <th>coréalisation</th>\n",
       "      <th>other</th>\n",
       "      <th>works</th>\n",
       "      <th>date_start</th>\n",
       "      <th>date_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>od_1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Le passé</td>\n",
       "      <td>Les cieux s’ouvrirent et… ici prit fin l’histo...</td>\n",
       "      <td>13 septembre—4 octobre</td>\n",
       "      <td>Odéon paris 6</td>\n",
       "      <td>['Léonid Andréïev']</td>\n",
       "      <td>['Julien Gosselin']</td>\n",
       "      <td>['Julien Gosselin']</td>\n",
       "      <td>...</td>\n",
       "      <td>['Si vous pouviez lécher mon coeur']</td>\n",
       "      <td>['Odéon théâtre de l’europe', 'Le phénix — scè...</td>\n",
       "      <td>['Ministère de la culture']</td>\n",
       "      <td>['Montévidéo — centre d’art', 'T2g théâtre de ...</td>\n",
       "      <td>programme de saison Odéon 25/26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Ékatérina Ivanovna']</td>\n",
       "      <td>13 September 2025</td>\n",
       "      <td>04 October 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>od_2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Musée duras</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9—30 novembre</td>\n",
       "      <td>Berthier paris 17</td>\n",
       "      <td>['Marguerite Duras']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julien Gosselin']</td>\n",
       "      <td>...</td>\n",
       "      <td>['Odéon théâtre de l’europe', 'Conservatoire n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Jeune théâtre national']</td>\n",
       "      <td>programme de saison Odéon 25/26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09 November 2025</td>\n",
       "      <td>30 November 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>od_3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Honda romance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14—26 octobre</td>\n",
       "      <td>Odéon paris 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Vimala Pons']</td>\n",
       "      <td>...</td>\n",
       "      <td>['Tout ça / que ça', 'Comédie de genève']</td>\n",
       "      <td>['Odéon théâtre de l’europe', 'Mc2 : maison de...</td>\n",
       "      <td>['Fondation bnp paribas']</td>\n",
       "      <td>['\"plateforme 2 pôles cirque en normandie — la...</td>\n",
       "      <td>programme de saison Odéon 25/26</td>\n",
       "      <td>['Festival d’Automne']</td>\n",
       "      <td>Festival d’Automne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14 October 2025</td>\n",
       "      <td>26 October 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>od_4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Pallaksch pallaksch!</td>\n",
       "      <td>Pièces élémentaires</td>\n",
       "      <td>26 novembre—14 février</td>\n",
       "      <td>Petit odéon paris 6</td>\n",
       "      <td>['D. H. Lawrence', 'Arthur Schnitzler', 'Hugo ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Marie-José Malis']</td>\n",
       "      <td>...</td>\n",
       "      <td>['Compagnie la llevantina']</td>\n",
       "      <td>['Odéon théâtre de l’europe', 'Comédie de genè...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>programme de saison Odéon 25/26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['La Coccinelle', 'Le Voile de Pierrette', 'Le...</td>\n",
       "      <td>26 November 2025</td>\n",
       "      <td>14 February 2026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  page_start  page_end                 titre  \\\n",
       "0  od_1           4         5              Le passé   \n",
       "1  od_2           7         7           Musée duras   \n",
       "2  od_3           8         8         Honda romance   \n",
       "3  od_4           9         9  Pallaksch pallaksch!   \n",
       "\n",
       "                                          sous-titre                   dates  \\\n",
       "0  Les cieux s’ouvrirent et… ici prit fin l’histo...  13 septembre—4 octobre   \n",
       "1                                                NaN           9—30 novembre   \n",
       "2                                                NaN           14—26 octobre   \n",
       "3                                Pièces élémentaires  26 novembre—14 février   \n",
       "\n",
       "                 salle                                             auteur  \\\n",
       "0        Odéon paris 6                                ['Léonid Andréïev']   \n",
       "1    Berthier paris 17                               ['Marguerite Duras']   \n",
       "2        Odéon paris 6                                                NaN   \n",
       "3  Petit odéon paris 6  ['D. H. Lawrence', 'Arthur Schnitzler', 'Hugo ...   \n",
       "\n",
       "            adaptation         mise en scène  ...  \\\n",
       "0  ['Julien Gosselin']   ['Julien Gosselin']  ...   \n",
       "1                  NaN   ['Julien Gosselin']  ...   \n",
       "2                  NaN       ['Vimala Pons']  ...   \n",
       "3                  NaN  ['Marie-José Malis']  ...   \n",
       "\n",
       "                                          production  \\\n",
       "0               ['Si vous pouviez lécher mon coeur']   \n",
       "1  ['Odéon théâtre de l’europe', 'Conservatoire n...   \n",
       "2          ['Tout ça / que ça', 'Comédie de genève']   \n",
       "3                        ['Compagnie la llevantina']   \n",
       "\n",
       "                                        coproduction  \\\n",
       "0  ['Odéon théâtre de l’europe', 'Le phénix — scè...   \n",
       "1                                                NaN   \n",
       "2  ['Odéon théâtre de l’europe', 'Mc2 : maison de...   \n",
       "3  ['Odéon théâtre de l’europe', 'Comédie de genè...   \n",
       "\n",
       "                       soutien  \\\n",
       "0  ['Ministère de la culture']   \n",
       "1                          NaN   \n",
       "2    ['Fondation bnp paribas']   \n",
       "3                          NaN   \n",
       "\n",
       "                                                aide  \\\n",
       "0  ['Montévidéo — centre d’art', 'T2g théâtre de ...   \n",
       "1                         ['Jeune théâtre national']   \n",
       "2  ['\"plateforme 2 pôles cirque en normandie — la...   \n",
       "3                                                NaN   \n",
       "\n",
       "                            source           coréalisation  \\\n",
       "0  programme de saison Odéon 25/26                     NaN   \n",
       "1  programme de saison Odéon 25/26                     NaN   \n",
       "2  programme de saison Odéon 25/26  ['Festival d’Automne']   \n",
       "3  programme de saison Odéon 25/26                     NaN   \n",
       "\n",
       "                other                                              works  \\\n",
       "0                 NaN                             ['Ékatérina Ivanovna']   \n",
       "1                 NaN                                                NaN   \n",
       "2  Festival d’Automne                                                NaN   \n",
       "3                 NaN  ['La Coccinelle', 'Le Voile de Pierrette', 'Le...   \n",
       "\n",
       "          date_start          date_end  \n",
       "0  13 September 2025   04 October 2025  \n",
       "1   09 November 2025  30 November 2025  \n",
       "2    14 October 2025   26 October 2025  \n",
       "3   26 November 2025  14 February 2026  \n",
       "\n",
       "[4 rows x 55 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=\"clean-csv.xlsx\"\n",
    "path= os.path.join(IN_FOLDER,file)\n",
    "df=pd.read_excel(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25848c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    \"\"\"Load JSON file or return None if not found.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data, path):\n",
    "    \"\"\"Save data as JSON file.\"\"\"\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def random_person_uri(base=\"https://data.stage.org/auth/\"):\n",
    "    \"\"\"Generate random person URI.\"\"\"\n",
    "    return base + uuid.uuid4().hex\n",
    "\n",
    "def is_empty_cell(x):\n",
    "    \"\"\"Check if cell value is empty.\"\"\"\n",
    "    if x is None:\n",
    "        return True\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return True\n",
    "    if isinstance(x, str) and x.strip() in (\"\", \"[]\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def parse_listlike_cell(val):\n",
    "    \"\"\"Parse Excel list-as-string like '[\"A\",\"B\"]' or list to list.\"\"\"\n",
    "    if val is None:\n",
    "        return []\n",
    "    if isinstance(val, list):\n",
    "        return [x for x in val if x is not None]\n",
    "    if isinstance(val, str):\n",
    "        s = val.strip()\n",
    "        if not s:\n",
    "            return []\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                out = ast.literal_eval(s)\n",
    "                return out if isinstance(out, list) else []\n",
    "            except Exception:\n",
    "                return []\n",
    "        return [s]\n",
    "    return []\n",
    "\n",
    "def parse_names_cell(val):\n",
    "    \"\"\"Parse names from cell value, returns list of strings.\"\"\"\n",
    "    names = parse_listlike_cell(val)\n",
    "    return [x.strip() for x in names if isinstance(x, str) and x.strip()]\n",
    "\n",
    "def parse_date_any(s):\n",
    "    \"\"\"Parse date from various formats.\"\"\"\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return None\n",
    "    \n",
    "    s = s.strip()\n",
    "    dt = dateparser.parse(\n",
    "        s,\n",
    "        languages=[\"fr\", \"en\"],\n",
    "        settings={\"TIMEZONE\": \"UTC\", \"RETURN_AS_TIMEZONE_AWARE\": False}\n",
    "    )\n",
    "    return dt\n",
    "\n",
    "def parse_year_from_date_start(date_str):\n",
    "    \"\"\"Extract year from date_start string.\"\"\"\n",
    "    if not isinstance(date_str, str) or not date_str.strip():\n",
    "        return None\n",
    "    dt = parse_date_any(date_str)\n",
    "    return dt.year if dt else None\n",
    "\n",
    "def to_iso_utc_midnight(dt):\n",
    "    \"\"\"Convert datetime to ISO format at midnight UTC.\"\"\"\n",
    "    return dt.strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "\n",
    "def daterange_inclusive(start_dt, end_dt):\n",
    "    \"\"\"Generate dates from start to end inclusive.\"\"\"\n",
    "    cur = start_dt\n",
    "    while cur <= end_dt:\n",
    "        yield cur\n",
    "        cur += timedelta(days=1)\n",
    "\n",
    "def load_person_index_csv(index_csv_path):\n",
    "    \"\"\"Load person index CSV, returns dict: person_name -> person_id.\"\"\"\n",
    "    df_idx = pd.read_csv(index_csv_path)\n",
    "    return dict(zip(df_idx[\"person_name\"], df_idx[\"person_id\"]))\n",
    "\n",
    "def save_person_index_csv(name_to_id, index_csv_path):\n",
    "    \"\"\"Save person index to CSV.\"\"\"\n",
    "    df_idx = pd.DataFrame(\n",
    "        [(pid, name) for name, pid in name_to_id.items()],\n",
    "        columns=[\"person_id\", \"person_name\"]\n",
    "    )\n",
    "    df_idx.to_csv(index_csv_path, index=False)\n",
    "\n",
    "def get_or_create_person_id(name, name_to_id):\n",
    "    \"\"\"Get existing person ID or create new one.\"\"\"\n",
    "    pid = name_to_id.get(name)\n",
    "    if not pid:\n",
    "        pid = random_person_uri()\n",
    "        name_to_id[name] = pid\n",
    "        warnings.warn(f\"[index] Missing person '{name}' -> generated new id: {pid}\")\n",
    "    return pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d367b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fragment_a(work_id, title, director_names, name_to_id):\n",
    "    \"\"\"Build Fragment A: Work with directors.\"\"\"\n",
    "    carried_out_by = []\n",
    "    \n",
    "    for name in director_names:\n",
    "        pid = get_or_create_person_id(name, name_to_id)\n",
    "        carried_out_by.append({\n",
    "            \"id\": pid,\n",
    "            \"type\": \"Person\",\n",
    "            \"_label\": name,\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"@context\": \"https://linked.art/ns/v1/linked-art.json\",\n",
    "        \"id\": f\"https://data.stage.org/works/{work_id}\",\n",
    "        \"type\": \"PropositionalObject\",\n",
    "        \"_label\": f\"{title} as conceived by {', '.join(director_names)}\",\n",
    "        \"classified_as\": [{\n",
    "            \"id\": \"https://vocab.getty.edu/aat/300387357\",\n",
    "            \"type\": \"Type\",\n",
    "            \"_label\": \"works (general, creative)\",\n",
    "        }],\n",
    "        \"identified_by\": [{\n",
    "            \"type\": \"Name\",\n",
    "            \"classified_as\": [{\n",
    "                \"id\": \"http://vocab.getty.edu/aat/300404670\",\n",
    "                \"type\": \"Type\",\n",
    "                \"_label\": \"Title\",\n",
    "            }],\n",
    "            \"content\": title,\n",
    "            \"language\": [{\n",
    "                \"id\": \"http://vocab.getty.edu/aat/300388306\",\n",
    "                \"type\": \"Language\",\n",
    "                \"label\": \"French\",\n",
    "            }],\n",
    "        }],\n",
    "        \"created_by\": [{\n",
    "            \"type\": \"Creation\",\n",
    "            \"part\": [{\n",
    "                \"type\": \"Production\",\n",
    "                \"technique\": [{\n",
    "                    \"id\": \"http://vocab.getty.edu/page/aat/300404387\",\n",
    "                    \"type\": \"Type\",\n",
    "                    \"_label\": \"Creating\",\n",
    "                }],\n",
    "                \"carried_out_by\": carried_out_by,\n",
    "            }],\n",
    "        }],\n",
    "    }\n",
    "\n",
    "def build_fragment_a_2(row, name_to_id, works_col, auteur_col):\n",
    "    \"\"\"Build Fragment A2: Influenced by (works or authors).\"\"\"\n",
    "    influenced_by = []\n",
    "    \n",
    "    works_val = row.get(works_col)\n",
    "    authors = parse_names_cell(row.get(auteur_col))\n",
    "    author_name = authors[0] if authors else \"\"\n",
    "    \n",
    "    # If no works, use author persons\n",
    "    if is_empty_cell(works_val):\n",
    "        for author in authors:\n",
    "            pid = get_or_create_person_id(author, name_to_id)\n",
    "            influenced_by.append({\n",
    "                \"id\": pid,\n",
    "                \"type\": \"Person\",\n",
    "                \"_label\": author\n",
    "            })\n",
    "    # If works present, create linguistic objects\n",
    "    else:\n",
    "        works = parse_names_cell(works_val)\n",
    "        for work_name in works:\n",
    "            influenced_by.append({\n",
    "                \"id\": f\"https://data.stage.org/text/{work_name}\",\n",
    "                \"type\": \"LinguisticObject\",\n",
    "                \"_label\": f\"{work_name} de {author_name}\".strip() if author_name else work_name,\n",
    "                \"classified_as\": [{\n",
    "                    \"id\": \"http://vocab.getty.edu/page/aat/300410356\",\n",
    "                    \"type\": \"Type\",\n",
    "                    \"_label\": \"Adaptation\"\n",
    "                }]\n",
    "            })\n",
    "    \n",
    "    return {\"influenced_by\": influenced_by}\n",
    "\n",
    "def build_fragment_a_3(row, date_start_col, source_id_col):\n",
    "    \"\"\"Build Fragment A3: Timespan and attribution.\"\"\"\n",
    "    source_id = row.get(source_id_col)\n",
    "    date_start = row.get(date_start_col)\n",
    "    \n",
    "    year = parse_year_from_date_start(date_start)\n",
    "    ts = None\n",
    "    if year:\n",
    "        ts = {\n",
    "            \"type\": \"TimeSpan\",\n",
    "            \"_label\": str(year),\n",
    "            \"begin_of_the_begin\": f\"{year}-01-01T00:00:00Z\",\n",
    "        }\n",
    "    \n",
    "    attributed_by = [{\n",
    "        \"type\": \"AttributeAssignment\",\n",
    "        \"identified_by\": [{\n",
    "            \"type\": \"Type\",\n",
    "            \"id\": \"https://vocab.getty.edu/aat/300027216\",\n",
    "            \"_label\": \"show programme\",\n",
    "            \"classified_as\": [{\n",
    "                \"id\": \"https://vocab.getty.edu/aat/300311936\",\n",
    "                \"type\": \"Type\",\n",
    "                \"_label\": \"primary source\",\n",
    "            }],\n",
    "        }],\n",
    "        \"assigned_property\": \"takes_information_from\",\n",
    "        \"assigned\": [{\n",
    "            \"type\": \"HumanMadeObject\",\n",
    "            \"id\": f\"https://data.stage.org/programs/{source_id}\",\n",
    "            \"_label\": str(source_id),\n",
    "        }],\n",
    "    }]\n",
    "    \n",
    "    return {\n",
    "        \"timespan\": ts,\n",
    "        \"attributed_by\": attributed_by\n",
    "    }\n",
    "\n",
    "def process_fragment_a_row(row, name_to_id, id_col, title_col, director_col, \n",
    "                          works_col, auteur_col, date_start_col, source_id_col, out_path):\n",
    "    \"\"\"Process one row for all Fragment A variants.\"\"\"\n",
    "    row_id = row.get(id_col)\n",
    "    title = row.get(title_col)\n",
    "    \n",
    "    if is_empty_cell(row_id) or is_empty_cell(title):\n",
    "        return\n",
    "    \n",
    "    row_id = str(row_id).strip()\n",
    "    title = str(title).strip()\n",
    "    \n",
    "    row_dir = os.path.join(out_path, row_id)\n",
    "    os.makedirs(row_dir, exist_ok=True)\n",
    "    \n",
    "    # Fragment A - main work\n",
    "    directors = parse_names_cell(row.get(director_col))\n",
    "    directors = list(dict.fromkeys(directors))  # Remove duplicates\n",
    "    fragment_a = build_fragment_a(row_id, title, directors, name_to_id)\n",
    "    save_json(fragment_a, os.path.join(row_dir, \"fragment_a.json\"))\n",
    "    \n",
    "    # Fragment A2 - influenced by\n",
    "    fragment_a_2 = build_fragment_a_2(row, name_to_id, works_col, auteur_col)\n",
    "    save_json(fragment_a_2, os.path.join(row_dir, \"fragment_a_2.json\"))\n",
    "    \n",
    "    # Fragment A3 - timespan and attribution\n",
    "    fragment_a_3 = build_fragment_a_3(row, date_start_col, source_id_col)\n",
    "    save_json(fragment_a_3, os.path.join(row_dir, \"fragment_a_3.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74f94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_from_folder(row_id, title, folder_path):\n",
    "    \"\"\"Assemble Fragment B from component fragments.\"\"\"\n",
    "    row_dir = os.path.join(folder_path, str(row_id))\n",
    "    \n",
    "    # Load fragments\n",
    "    title_frag = load_json(os.path.join(row_dir, \"b-production\",\"b-title.json\"))\n",
    "    place_frag = load_json(os.path.join(row_dir, \"b-production\",\"b-place.json\"))\n",
    "    creative_frag = load_json(os.path.join(row_dir, \"b-production\", \"b-creative.json\"))\n",
    "    prod_frag = load_json(os.path.join(row_dir, \"b-production\", \"b-prod.json\"))\n",
    "    timespan_frag = load_json(os.path.join(row_dir, \"b-production\", \"b-timespan.json\"))\n",
    "    \n",
    "    # Build final structure\n",
    "    final = {\n",
    "        \"@context\": \"https://linked.art/ns/v1/linked-art.json\",\n",
    "        \"id\": f\"https://data.stage.org/prod/{row_id}\",\n",
    "        \"type\": \"Activity\",\n",
    "        \"_label\": title,\n",
    "        \"classified_as\": [{\n",
    "            \"id\": \"https://vocab.getty.edu/aat/300069200\",\n",
    "            \"type\": \"Type\",\n",
    "            \"_label\": \"Performances (creative events)\",\n",
    "            \"classified_as\": [{\n",
    "                \"id\": \"https://vocab.getty.edu/aat/300417582\",\n",
    "                \"type\": \"Type\",\n",
    "                \"_label\": \"Theater (genre)\",\n",
    "            }],\n",
    "        }],\n",
    "        \"produced_by\": [{\"type\": \"Production\", \"part\": []}],\n",
    "    }\n",
    "    \n",
    "    # Add title and place\n",
    "    for frag in (title_frag, place_frag):\n",
    "        if isinstance(frag, dict):\n",
    "            final.update(frag)\n",
    "    \n",
    "    # Add creative and production parts\n",
    "    for frag in (creative_frag, prod_frag):\n",
    "        if not isinstance(frag, dict):\n",
    "            continue\n",
    "        if \"part\" in frag and isinstance(frag[\"part\"], list):\n",
    "            final[\"produced_by\"][0][\"part\"].extend(frag[\"part\"])\n",
    "        elif \"technique\" in frag and \"carried_out_by\" in frag:\n",
    "            final[\"produced_by\"][0][\"part\"].append(frag)\n",
    "    \n",
    "    # Add timespan\n",
    "    if isinstance(timespan_frag, dict):\n",
    "        final[\"timespan\"] = timespan_frag\n",
    "    \n",
    "    return final\n",
    "\n",
    "def process_fragment_b_row(row, id_col, title_col, folder_path):\n",
    "    \"\"\"Process one row for Fragment B.\"\"\"\n",
    "    row_id = row.get(id_col)\n",
    "    title = row.get(title_col)\n",
    "    \n",
    "    if is_empty_cell(row_id):\n",
    "        return\n",
    "    \n",
    "    title = title if isinstance(title, str) else \"\"\n",
    "    row_dir = os.path.join(folder_path, str(row_id))\n",
    "    os.makedirs(row_dir, exist_ok=True)\n",
    "    \n",
    "    final = assemble_from_folder(row_id, title, folder_path)\n",
    "    save_json(final, os.path.join(row_dir, \"b-production\", \"b-final.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af01b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "198c18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_C_for_date(row_id, title, odeon_id, iso_date, duration_minutes):\n",
    "    \"\"\"Build Fragment C for a specific date.\"\"\"\n",
    "    date_suffix = iso_date[:10].replace(\"-\", \"\")  # YYYYMMDD\n",
    "    \n",
    "    return {\n",
    "        \"@context\": \"https://linked.art/ns/v1/linked-art.json\",\n",
    "        \"id\": f\"https://data.stage.org/shows/{row_id}_{date_suffix}\",\n",
    "        \"type\": \"Activity\",\n",
    "        \"_label\": f\"Specific Dates for {title} at Odéon\",\n",
    "        \"part_of\": [{\n",
    "            \"id\": f\"https://data.stage.org/prod/{row_id}\",\n",
    "            \"type\": \"Activity\",\n",
    "            \"_label\": f\"Production {title} at Odéon\",\n",
    "        }],\n",
    "        \"classified_as\": [{\n",
    "            \"id\": \"http://vocab.getty.edu/page/aat/300XXXXXX\",\n",
    "            \"type\": \"Type\",\n",
    "            \"_label\": \"performance (performing arts show) to be defined in Getty\",\n",
    "        }],\n",
    "        \"timespan\": {\n",
    "            \"type\": \"TimeSpan\",\n",
    "            \"_label\": \"Date\",\n",
    "            \"begin_of_the_begin\": iso_date,\n",
    "            \"duration\": {\n",
    "                \"type\": \"Dimension\",\n",
    "                \"value\": duration_minutes,\n",
    "                \"unit\": {\n",
    "                    \"id\": \"http://vocab.getty.edu/aat/300379240\",\n",
    "                    \"type\": \"MeasurementUnit\",\n",
    "                    \"_label\": \"minutes\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"attributed_by\": [{\n",
    "            \"type\": \"AttributeAssignment\",\n",
    "            \"identified_by\": [{\n",
    "                \"type\": \"Type\",\n",
    "                \"id\": \"https://vocab.getty.edu/aat/300027216\",\n",
    "                \"_label\": \"show programme\",\n",
    "                \"classified_as\": [{\n",
    "                    \"id\": \"https://vocab.getty.edu/aat/300311936\",\n",
    "                    \"type\": \"Type\",\n",
    "                    \"_label\": \"primary source\",\n",
    "                }],\n",
    "            }],\n",
    "            \"assigned_property\": \"takes_information_from\",\n",
    "            \"assigned\": [{\n",
    "                \"type\": \"HumanMadeObject\",\n",
    "                \"id\": f\"https://data.stage.org/programs/{odeon_id}\",\n",
    "                \"_label\": str(odeon_id),\n",
    "            }],\n",
    "        }],\n",
    "    }\n",
    "\n",
    "def process_fragment_c_row(row, id_col, title_col, duration_col, odeon_id_col, \n",
    "                          start_col, end_col, out_dir):\n",
    "    \"\"\"Process one row for Fragment C (all dates).\"\"\"\n",
    "    row_id = row.get(id_col)\n",
    "    \n",
    "    if is_empty_cell(row_id):\n",
    "        return\n",
    "    \n",
    "    title = row.get(title_col)\n",
    "    odeon_id = row.get(odeon_id_col)\n",
    "    duration = row.get(duration_col)\n",
    "    \n",
    "    if is_empty_cell(title):\n",
    "        return\n",
    "    \n",
    "    # Parse duration\n",
    "    try:\n",
    "        duration_minutes = int(duration)\n",
    "    except Exception:\n",
    "        duration_minutes = None\n",
    "    \n",
    "    # Parse dates\n",
    "    start_dt = parse_date_any(row.get(start_col))\n",
    "    end_dt = parse_date_any(row.get(end_col))\n",
    "    \n",
    "    if not start_dt or not end_dt:\n",
    "        return\n",
    "    \n",
    "    # Normalize to midnight\n",
    "    start_dt = start_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    end_dt = end_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    \n",
    "    # Build collection for all dates\n",
    "    collection = []\n",
    "    for dt in daterange_inclusive(start_dt, end_dt):\n",
    "        iso = to_iso_utc_midnight(dt)\n",
    "        collection.append(build_C_for_date(\n",
    "            row_id=str(row_id),\n",
    "            title=str(title).strip(),\n",
    "            odeon_id=odeon_id,\n",
    "            iso_date=iso,\n",
    "            duration_minutes=duration_minutes,\n",
    "        ))\n",
    "    \n",
    "    # Save\n",
    "    out_path = os.path.join(out_dir, f\"c_{row_id}.json\")\n",
    "    save_json(collection, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b115ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_fragments(df, out_path, index_csv_path):\n",
    "    \"\"\"Process all fragments (A, B, C) for entire dataframe.\"\"\"\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    \n",
    "    # Load person index\n",
    "    name_to_id = load_person_index_csv(index_csv_path)\n",
    "    \n",
    "    # Process each row\n",
    "    for _, row in df.iterrows():\n",
    "        # Fragment A (all variants)\n",
    "        process_fragment_a_row(\n",
    "            row, name_to_id,\n",
    "            id_col=\"ID\",\n",
    "            title_col=\"titre\",\n",
    "            director_col=\"mise en scène\",\n",
    "            works_col=\"works\",\n",
    "            auteur_col=\"auteur\",\n",
    "            date_start_col=\"date_start\",\n",
    "            source_id_col=\"source\",\n",
    "            out_path=out_path\n",
    "        )\n",
    "        \n",
    "        # Fragment B\n",
    "        process_fragment_b_row(\n",
    "            row,\n",
    "            id_col=\"ID\",\n",
    "            title_col=\"titre\",\n",
    "            folder_path=out_path\n",
    "        )\n",
    "        \n",
    "        # Fragment C\n",
    "        process_fragment_c_row(\n",
    "            row,\n",
    "            id_col=\"ID\",\n",
    "            title_col=\"titre\",\n",
    "            duration_col=\"durée\",\n",
    "            odeon_id_col=\"source\",\n",
    "            start_col=\"date_start\",\n",
    "            end_col=\"date_end\",\n",
    "            out_dir=out_path\n",
    "        )\n",
    "    \n",
    "    # Save updated person index\n",
    "    save_person_index_csv(name_to_id, index_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9cc1ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 rows from clean-csv.xlsx\n",
      "\n",
      "Processing complete. Output saved to ../data/json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    file = \"clean-csv.xlsx\"\n",
    "    path = os.path.join(IN_FOLDER, file)\n",
    "    df = pd.read_excel(path)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} rows from {file}\")\n",
    "    \n",
    "    # Process all fragments\n",
    "    index_csv_path = os.path.join(IN_FOLDER, \"person_index.csv\")\n",
    "    process_all_fragments(df, OUT_FOLDER, index_csv_path)\n",
    "    \n",
    "    print(f\"\\nProcessing complete. Output saved to {OUT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 rows from clean-csv.xlsx\n",
      "\n",
      "Assembling final_a.json files from fragments...\n",
      "Output directory: ../data/json\n",
      "\n",
      "✓ Created final_a.json for od_1\n",
      "✓ Created final_a.json for od_2\n",
      "✓ Created final_a.json for od_3\n",
      "✓ Created final_a.json for od_4\n",
      "\n",
      "✓ Processed 4 rows\n",
      "\n",
      "✓ Assembly complete. Files saved to ../data/json\n"
     ]
    }
   ],
   "source": [
    "def assemble_final_a(row_id, folder_path):\n",
    "    \"\"\"Assemble final_a.json from fragment_a, fragment_a_2, and fragment_a_3.\"\"\"\n",
    "    row_dir = os.path.join(folder_path, str(row_id))\n",
    "    \n",
    "    # Load fragments\n",
    "    fragment_a = load_json(os.path.join(row_dir, \"fragment_a.json\"))\n",
    "    fragment_a_2 = load_json(os.path.join(row_dir, \"fragment_a_2.json\"))\n",
    "    fragment_a_3 = load_json(os.path.join(row_dir, \"fragment_a_3.json\"))\n",
    "    \n",
    "    if not fragment_a:\n",
    "        print(f\"Warning: fragment_a.json not found for {row_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Start with fragment_a as base\n",
    "    final_a = fragment_a.copy()\n",
    "    \n",
    "    # Add influenced_by from fragment_a_2\n",
    "    if fragment_a_2 and \"influenced_by\" in fragment_a_2:\n",
    "        final_a[\"influenced_by\"] = fragment_a_2[\"influenced_by\"]\n",
    "    \n",
    "    # Add timespan and attributed_by from fragment_a_3\n",
    "    if fragment_a_3:\n",
    "        if \"timespan\" in fragment_a_3:\n",
    "            final_a[\"timespan\"] = fragment_a_3[\"timespan\"]\n",
    "        if \"attributed_by\" in fragment_a_3:\n",
    "            final_a[\"attributed_by\"] = fragment_a_3[\"attributed_by\"]\n",
    "    \n",
    "    return final_a\n",
    "\n",
    "def process_final_a_row(row, id_col, folder_path):\n",
    "    \"\"\"Process one row for final_a assembly.\"\"\"\n",
    "    row_id = row.get(id_col)\n",
    "    \n",
    "    if is_empty_cell(row_id):\n",
    "        return\n",
    "    \n",
    "    row_id = str(row_id).strip()\n",
    "    row_dir = os.path.join(folder_path, row_id)\n",
    "    \n",
    "    final_a = assemble_final_a(row_id, folder_path)\n",
    "    \n",
    "    if final_a:\n",
    "        output_path = os.path.join(row_dir, \"final_a.json\")\n",
    "        save_json(final_a, output_path)\n",
    "        print(f\"✓ Created final_a.json for {row_id}\")\n",
    "    else:\n",
    "        print(f\"✗ Failed to create final_a.json for {row_id}\")\n",
    "\n",
    "def assemble_all_final_a(df, out_path, id_col=\"ID\"):\n",
    "    \"\"\"Assemble final_a.json for all rows in dataframe.\"\"\"\n",
    "    print(f\"Assembling final_a.json files from fragments...\")\n",
    "    print(f\"Output directory: {out_path}\\n\")\n",
    "    \n",
    "    count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        process_final_a_row(row, id_col=id_col, folder_path=out_path)\n",
    "        count += 1\n",
    "    \n",
    "    print(f\"\\n✓ Processed {count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    file = \"clean-csv.xlsx\"\n",
    "    path = os.path.join(IN_FOLDER, file)\n",
    "    df = pd.read_excel(path)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} rows from {file}\\n\")\n",
    "    \n",
    "    # Assemble all final_a files\n",
    "    assemble_all_final_a(df, OUT_FOLDER, id_col=\"ID\")\n",
    "    \n",
    "    print(f\"\\n✓ Assembly complete. Files saved to {OUT_FOLDER}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
